---
title: "558_Project_3"
author: "ankit gupta & brian higginbotham"
date: "2023-11-08"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, error = FALSE)
```

# Introduction

# Data

# Summarizations

# Modeling

## LogLoss

LogLoss is a performance measurement that measures the distance between correct outcome (1 or 0) and the calculated probability. So the closer the model prediction is to the actual outcome, the lower the LogLoss score is. 

LogLoss can be a better way of measuring the performance as compared to an Accuracy rating. If a model predicted 0.51 probability as True and the actual result was True, this would be marked as a correct outcome in an accuracy rating. But in reality, the model barely got the prediction right and this may result in poor performance when the model is implemented on new data. LogLoss records this measured discrepancy and thus may provide a better description of the models performance. LogLoss is similar to the Residual Mean Squared Error (RMSE) produced in linear regression models.

## Logistic Regression

Logistic Regression is a Generalized Linear Model that models the probability of a binary outcome (success or failure, 1 or 0, etc). A Simple Linear Regression model would produce a continuous response on the real line that would not correspond to the predictions we are trying to make, so we use a logistic function that produces a logit or log-odds of success that is linear in its parameters. The logit or log-odds is then used to determine the outcome, generally split at probability 0.5 (greater than 0.5 = success, less than 0.5 = failure).